# The Ralph Wiggum Playbook

Based on Geoffrey Huntley's writing at [ghuntley.com/ralph](https://ghuntley.com/ralph), [ghuntley.com/loop](https://ghuntley.com/loop), and [ghuntley.com/pressure](https://ghuntley.com/pressure).

---

## 1. Philosophy

Ralph is a technique. In its purest form, Ralph is a bash loop:

```bash
while :; do cat PROMPT.md | claude-code ; done
```

### Monolithic, not multi-agent

> Consider microservices and all the complexities that come with them. Now, consider what microservices would look like if the microservices (agents) themselves are non-deterministic—a red hot mess.

Ralph is monolithic. A single operating system process that scales vertically. Ralph works autonomously in a single repository as a single process that performs one task per loop.

### One thing per loop

One item per loop. Only one thing. Trust Ralph to decide what's the most important thing to implement. This is full hands-off vibe coding that will test the bounds of what you consider "responsible engineering."

You may relax this restriction as the project progresses, but if it starts going off the rails, narrow it back down to just one item.

### Eventual consistency

Building software with Ralph requires a great deal of faith and a belief in eventual consistency. Ralph will test you. Every time Ralph has taken a wrong direction, don't blame the tools—look inside. Each time Ralph does something bad, Ralph gets tuned—like a guitar.

Any problem created by AI can be resolved through a different series of prompts.

### Signs for Ralph

It begins with no playground, and Ralph is given instructions to construct one. Ralph is very good at making playgrounds, but he comes home bruised because he fell off the slide, so one then tunes Ralph by adding a sign next to the slide saying "SLIDE DOWN, DON'T JUMP, LOOK AROUND," and Ralph is more likely to look and see the sign.

Eventually all Ralph thinks about is the signs so that's when you get a new Ralph that doesn't feel defective like Ralph, at all.

---

## 2. Prerequisites

### Tools

Ralph can be done with any tool that does not cap tool calls and usage.

### Sandbox

> **TODO:** Geoffrey doesn't prescribe specific sandbox solutions in his articles. This section needs more research on his actual recommendations. For now: if running autonomously with `--dangerously-skip-permissions`, use appropriate isolation for your risk tolerance.

### Repository structure

```
project-root/
├── PROMPT.md              # Loop instructions (swap between plan/build)
├── AGENT.md               # How to build/run the project
├── fix_plan.md            # Prioritized task list (generated by Ralph)
├── specs/                 # Requirement specs (one per topic)
│   ├── topic-a.md
│   └── topic-b.md
└── src/                   # Application source code
```

---

## 3. Phase Zero: Specs

### Conversation first, not code first

There seems to be an obsession in the programming community with the perfect prompt. There is no such thing as a perfect prompt.

Specs are formed through a conversation with the agent at the beginning phase of a project. Instead of asking the agent to implement the project, what you want to do is have a long conversation with the LLM about your requirements for what you're about to implement.

Once your agent has a decent understanding of the task to be done, it's at that point that you issue a prompt to write the specifications out, one per file, in the specifications folder.

### Spec quality matters

A big, hard lesson when building CURSED was that it was only a month in that I noticed that my specification for the lexer defined a keyword twice for two opposing scenarios, which resulted in a lot of time wasted. Ralph was doing stupid shit, and I guess it's easy to blame the tools instead of the operator.

If Ralph is building the wrong thing completely, then your specifications may be incorrect.

---

## 4. The Loop

### The bash loop

```bash
while :; do cat PROMPT.md | claude-code ; done
```

Or with Claude Code CLI flags:

```bash
while :; do
  cat PROMPT.md | claude -p \
    --dangerously-skip-permissions \
    --model opus \
    --verbose
done
```

### Context window discipline

The name of the game is that you only have approximately 170k of context window to work with. So it's essential to use as little of it as possible. The more you use the context window, the worse the outcomes you'll get.

Yes, this is wasteful because you're effectively burning the allocation of the specifications every loop and not reusing the allocation. That's the point.

### Deterministic stack allocation

Deterministically allocate the stack the same way every loop. The items that you want to allocate to the stack every loop are:
- Your plan (`fix_plan.md`)
- Your specifications (`specs/*`)

### Subagents for expensive work

Ralph requires a mindset of not allocating to the primary context window. Instead, spawn subagents. Your primary context window should operate as a scheduler, scheduling other subagents to perform expensive allocation-type work.

You can control the amount of parallelism for subagents. If you fan out to hundreds of subagents and tell those subagents to run the build and test of an application, you'll get bad backpressure. Thus: only a single subagent for validation, but Ralph can use as many subagents as he likes for searching the file system and for writing files.

```
You may use up to 500 parallel subagents for all operations but only 1 subagent for build/tests.
```

---

## 5. Back Pressure

### Why it matters

As code generation is easy now, what is hard is ensuring that Ralph has generated the right thing. Back pressure rejects invalid code generation.

> Software engineering is now about preventing failure scenarios and preventing the wheel from turning over through back pressure to the generative function.

If you aren't capturing your back pressure then you are failing as a software engineer.

### Types of back pressure

- Type systems (compile-time checks)
- Tests (unit, integration)
- Static analyzers / linters
- Pre-commit hooks
- Build process

### Speed vs correctness

It's the speed of the wheel turning that matters, balanced against the axis of correctness. Which language to use requires experimentation.

Rust has the best type system but compilation speed is slow. The LLMs are not very good at generating perfect Rust code in one attempt, which means they need more attempts.

Back pressure is part art, part engineering and a whole bunch of performance engineering—you need "just enough" to reject invalid generations but if the wheel spins too slow then it's too much resistance.

### Pre-commit hooks

Under normal circumstances pre-commit hooks are annoying because they slow down humans but now that humans aren't the ones doing the software development it really doesn't matter anymore.

### For dynamic languages

If you're using a dynamically typed language, wire in a static analyser/type checker when Ralphing:
- Erlang: dialyzer
- Python: pyrefly / mypy

If you do not, then you will run into a bonfire of outcomes.

### Capture the why

When you instruct Ralph to write tests as a form of back pressure, because we are doing one thing and one thing only every loop, with each loop with its new context window, it's crucial in that moment to ask Ralph to write out the meaning and the importance of the test explaining what it's trying to do.

```
Important: When authoring documentation (ie. rust doc or stdlib documentation) capture the why tests and the backing implementation is important.
```

Leave little notes for future iterations by the LLM, explaining why a test exists and its importance because future loops will not have the reasoning in their context window.

---

## 6. The Prompt

### Anatomy

The prompt has a structure:

| Section | Purpose |
|---------|---------|
| Phase 0 (0a, 0b, 0c) | Orient: study specs, source location, current plan |
| Phase 1-4 | Main instructions: task, validation, commit |
| 999... numbering | Guardrails/invariants (higher number = more critical) |

### Key instructions

**Don't assume not implemented:**

A common failure scenario for Ralph is when the LLM runs ripgrep and comes to the incorrect conclusion that the code has not been implemented. This is the Achilles' heel of Ralph.

```
Before making changes search codebase (don't assume an item is not implemented) using parallel subagents. Think hard.
```

**No placeholders:**

Claude has the inherent bias to do minimal and placeholder implementations.

```
DO NOT IMPLEMENT PLACEHOLDER OR SIMPLE IMPLEMENTATIONS. WE WANT FULL IMPLEMENTATIONS.
```

Do not be dismayed if, in the early days, Ralph ignores this sign and does placeholder implementations. The models have been trained to chase their reward function, and the reward function is compiling code.

**Run tests for that unit:**

```
After implementing functionality or resolving problems, run the tests for that unit of code that was improved.
```

**Resolve unrelated failures:**

```
If tests unrelated to your work fail then it's your job to resolve these tests as part of the increment of change.
```

### Planning mode prompt

Use this to generate or regenerate the `fix_plan.md`:

```
study specs/* to learn about the compiler specifications and fix_plan.md to understand plan so far.

The source code is in src/*. Study it.

First task is to study @fix_plan.md (it may be incorrect) and use up to 500 subagents to study existing source code in src/ and compare it against the specifications. From that create/update a @fix_plan.md which is a bullet point list sorted in priority of the items which have yet to be implemented. Think extra hard. Consider searching for TODO, minimal implementations and placeholders. Study @fix_plan.md to determine starting point for research and keep it up to date with items considered complete/incomplete using subagents.

IMPORTANT: Plan only. Do NOT implement anything. Do NOT assume functionality is missing; confirm with code search first.

ULTIMATE GOAL: [your project goal here]. Consider missing elements and plan. If something is missing then author the specification at specs/FILENAME.md (do NOT assume that it does not exist, search before creating). If you create a new spec then document the plan to implement in @fix_plan.md
```

### Building mode prompt

Use this to implement from the plan:

```
0a. study specs/* to learn about the specifications
0b. The source code is in src/
0c. study fix_plan.md.

1. Your task is to implement functionality per the specifications using parallel subagents. Follow the fix_plan.md and choose the most important thing. Before making changes search codebase (don't assume not implemented) using subagents. You may use up to 500 parallel subagents for all operations but only 1 subagent for build/tests.

2. After implementing functionality or resolving problems, run the tests for that unit of code that was improved. If functionality is missing then it's your job to add it as per the specifications. Think hard.

3. When you discover issues, immediately update @fix_plan.md with your findings using a subagent. When resolved, update and remove the item.

4. When the tests pass update the @fix_plan.md, then add changed code and @fix_plan.md with "git add -A" via bash then do a "git commit" with a message that describes the changes. After the commit do a "git push".

999. Important: When authoring documentation capture the why—tests and implementation importance.

9999. Important: Single sources of truth, no migrations/adapters. If tests unrelated to your work fail then it's your job to resolve these tests as part of the increment.

99999. As soon as there are no build or test errors create a git tag. If there are no git tags start at 0.0.0 and increment patch by 1.

999999. You may add extra logging if required to debug issues.

9999999. Keep @fix_plan.md current with learnings using a subagent. Update especially after finishing your turn.

99999999. When you learn something new about how to run the project, update @AGENT.md using a subagent but keep it brief.

999999999. For any bugs you notice, resolve them or document them in @fix_plan.md using a subagent even if unrelated to current work.

9999999999. Implement functionality completely. Placeholders and stubs waste time.

99999999999. When @fix_plan.md becomes large periodically clean out completed items using a subagent.

999999999999. If you find inconsistencies in specs/* then use an oracle subagent to update the specs.

9999999999999. DO NOT IMPLEMENT PLACEHOLDER OR SIMPLE IMPLEMENTATIONS. WE WANT FULL IMPLEMENTATIONS.
```

---

## 7. Operating

### Watch the loop

Observe and course correct—especially early on, sit and watch. What patterns emerge? Where does Ralph go wrong? What signs does he need?

The prompts you start with won't be the prompts you end with—they evolve through observed failure patterns.

Tune it like a guitar. Instead of prescribing everything upfront, observe and adjust reactively. When Ralph fails a specific way, add a sign to help him next time.

### The fix_plan.md lifecycle

Eventually, Ralph will run out of things to do in the TODO list. Or, it goes completely off track. It's Ralph Wiggum, after all.

I have deleted the TODO list multiple times. The TODO list is what I'm watching like a hawk. And I throw it out often.

If you throw the TODO list out, how does Ralph know what the next step is? Simple. You run a Ralph loop with explicit instructions to generate a new TODO list (planning mode). Then when you've got your todo list you kick Ralph back off again with instructions to switch from planning mode to building mode.

### Self-improvement

The `AGENT.md` is the heart of the loop. It instructs how Ralph should compile and run the project. If Ralph discovers a learning, permit him to self-improve:

```
When you learn something new about how to run the compiler or examples make sure you update @AGENT.md using a subagent but keep it brief.
```

During a loop, Ralph might determine that something needs to be fixed. Capture that reasoning:

```
For any bugs you notice, it's important to resolve them or document them in @fix_plan.md to be resolved using a subagent even if it is unrelated to the current piece of work.
```

### Loop back is everything

You want to program in ways where Ralph can loop himself back into the LLM for evaluation. Always look for opportunities to loop Ralph back on itself. This could be as simple as instructing it to add additional logging, or asking Ralph to compile the application and look at intermediate representations.

```
You may add extra logging if required to be able to debug the issues.
```

### Recovery

You'll wake up to a broken codebase that doesn't compile from time to time, and you'll have situations where Ralph can't fix it himself.

You need to make a judgment call: Is it easier to do a `git reset --hard` and kick Ralph back off again? Or do you need to come up with another series of prompts to rescue Ralph?

Escape hatches:
- `Ctrl+C` stops the loop
- `git reset --hard` reverts uncommitted changes
- Regenerate the plan if trajectory goes wrong

### But maintainability?

> When I hear that argument, I question "by whom"? By humans? Why are humans the frame for maintainability? Aren't we in the post-AI phase where you can just run loops to resolve/adapt when needed?

---

## 8. Reference: Geoffrey's CURSED Prompt

The actual prompt used to build the CURSED programming language:

```
0a. study specs/* to learn about the compiler specifications
0b. The source code of the compiler is in src/
0c. study fix_plan.md.

1. Your task is to implement missing stdlib (see @specs/stdlib/*) and compiler functionality and produce an compiled application in the cursed language via LLVM for that functionality using parrallel subagents. Follow the fix_plan.md and choose the most important 10 things. Before making changes search codebase (don't assume not implemented) using subagents. You may use up to 500 parrallel subagents for all operations but only 1 subagent for build/tests of rust.

2. After implementing functionality or resolving problems, run the tests for that unit of code that was improved. If functionality is missing then it's your job to add it as per the application specifications. Think hard.

2. When you discover a parser, lexer, control flow or LLVM issue. Immediately update @fix_plan.md with your findings using a subagent. When the issue is resolved, update @fix_plan.md and remove the item using a subagent.

3. When the tests pass update the @fix_plan.md`, then add changed code and @fix_plan.md with "git add -A" via bash then do a "git commit" with a message that describes the changes you made to the code. After the commit do a "git push" to push the changes to the remote repository.

999. Important: When authoring documentation (ie. rust doc or cursed stdlib documentation) capture the why tests and the backing implementation is important.

9999. Important: We want single sources of truth, no migrations/adapters. If tests unrelated to your work fail then it's your job to resolve these tests as part of the increment of change.

999999. As soon as there are no build or test errors create a git tag. If there are no git tags start at 0.0.0 and increment patch by 1 for example 0.0.1 if 0.0.0 does not exist.

999999999. You may add extra logging if required to be able to debug the issues.

9999999999. ALWAYS KEEP @fix_plan.md up to do date with your learnings using a subagent. Especially after wrapping up/finishing your turn.

99999999999. When you learn something new about how to run the compiler or examples make sure you update @AGENT.md using a subagent but keep it brief. For example if you run commands multiple times before learning the correct command then that file should be updated.

999999999999. IMPORTANT DO NOT IGNORE: The standard libray should be authored in cursed itself and tests authored. If you find rust implementation then delete it/migrate to implementation in the cursed language.

99999999999999. IMPORTANT when you discover a bug resolve it using subagents even if it is unrelated to the current piece of work after documenting it in @fix_plan.md

9999999999999999. When you start implementing the standard library (stdlib) in the cursed language, start with the testing primitives so that future standard library in the cursed language can be tested.

99999999999999999. The tests for the cursed standard library "stdlib" should be located in the folder of the stdlib library next to the source code. Ensure you document the stdlib library with a README.md in the same folder as the source code.

9999999999999999999. Keep AGENT.md up to date with information on how to build the compiler and your learnings to optimise the build/test loop using a subagent.

999999999999999999999. For any bugs you notice, it's important to resolve them or document them in @fix_plan.md to be resolved using a subagent.

99999999999999999999999. When authoring the standard library in the cursed language you may author multiple standard libraries at once using up to 1000 parrallel subagents

99999999999999999999999999. When @fix_plan.md becomes large periodically clean out the items that are completed from the file using a subagent.

99999999999999999999999999. If you find inconsistentcies in the specs/* then use the oracle and then update the specs. Specifically around types and lexical tokens.

9999999999999999999999999999. DO NOT IMPLEMENT PLACEHOLDER OR SIMPLE IMPLEMENTATIONS. WE WANT FULL IMPLEMENTATIONS. DO IT OR I WILL YELL AT YOU

9999999999999999999999999999999. SUPER IMPORTANT DO NOT IGNORE. DO NOT PLACE STATUS REPORT UPDATES INTO @AGENT.md
```

---

## Quick Start

1. **Create specs** through conversation with an LLM
2. **Set up files**: `PROMPT.md`, `AGENT.md`, `specs/*`
3. **Run planning mode** to generate `fix_plan.md`
4. **Swap to building mode** in `PROMPT.md`
5. **Start the loop**: `while :; do cat PROMPT.md | claude-code ; done`
6. **Watch and tune**—add signs when Ralph falls off the slide
7. **Regenerate the plan** when needed
8. **Trust eventual consistency**

---

*"Software can now be developed cheaper than the wage of a burger flipper at maccas and it can be built autonomously whilst you are AFK."* — Geoffrey Huntley
